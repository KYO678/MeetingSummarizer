import streamlit as st
import tempfile
import os
import subprocess
import json
from pathlib import Path
from datetime import datetime
from openai import OpenAI
from notion_client import Client

# ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆãƒã‚¤ãƒˆå˜ä½ï¼‰
MAX_SIZE = 25 * 1024 * 1024  # 25MB (Whisper APIã®åˆ¶é™)

def check_password():
    """
    ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡æ©Ÿèƒ½
    """
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    
    # ã™ã§ã«èªè¨¼æ¸ˆã¿ãªã‚‰ã€Trueã‚’è¿”ã™
    if st.session_state["password_correct"]:
        return True
    
    # æ­£ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ (st.secrets ã‹ã‚‰èª­ã¿è¾¼ã¿)
    correct_password = st.secrets.get("APP_PASSWORD", "")
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º - f-stringå†…ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’é¿ã‘ã‚‹ãŸã‚å¤‰æ•°ã‚’å…ˆã«å®šç¾©
    auth_status = "èªè¨¼æ¸ˆã¿" if st.session_state["password_correct"] else "æœªèªè¨¼"
    st.write(f"ç¾åœ¨ã®èªè¨¼çŠ¶æ…‹: {auth_status}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    st.markdown("### ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›")
    password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password", key="password_input")
    
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³", key="login_button"):
        if password == correct_password:
            st.session_state["password_correct"] = True
            # experimental_rerunã‚’st.rerun()ã«å¤‰æ›´
            st.rerun()  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®æ›´æ–°ã‚’åæ˜ ã•ã›ã‚‹ãŸã‚ã«å†å®Ÿè¡Œ
            return True
        else:
            st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
            return False
    
    return False

def load_config():
    """
    st.secrets ã‹ã‚‰è¨­å®šæƒ…å ±ï¼ˆAPIã‚­ãƒ¼ãªã©ï¼‰ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚
    """
    # è¨­å®š
    config = {
        "openai": {"api_key": st.secrets.get("OPENAI_API_KEY", "")},
        "notion": {
            "api_key": st.secrets.get("NOTION_API_KEY", ""),
            "database_id": st.secrets.get("NOTION_DATABASE_ID", "")
        }
    }
    
    return config

def get_file_metadata(file):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™
    :param file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    :return: ãƒ•ã‚¡ã‚¤ãƒ«åã¨ä½œæˆæ—¥æ™‚ã®ã‚¿ãƒ—ãƒ«
    """
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ä¿å­˜
    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.name).suffix) as tmp_file:
        tmp_file.write(file.getvalue())
        tmp_path = tmp_file.name
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—ï¼ˆæ‹¡å¼µå­ã‚‚å«ã‚€ï¼‰
    filename = Path(file.name).name
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆã€ç¾åœ¨ã®æ—¥æ™‚ã‚’ä½¿ç”¨
    creation_date = datetime.now().strftime('%Y-%m-%d')
    
    # FFmpegãŒã‚ã‚‹ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
    ffmpeg_available = False
    try:
        subprocess.run(["ffprobe", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        ffmpeg_available = True
    except (subprocess.SubprocessError, FileNotFoundError):
        # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’éè¡¨ç¤ºã«ã™ã‚‹ã‹ã€ã‚ˆã‚Šæƒ…å ±çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›´
        st.info("è©³ç´°ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã¯çœç•¥ã•ã‚Œã¾ã™ï¼ˆFFmpegéå¯¾å¿œç’°å¢ƒï¼‰")
    
    if ffmpeg_available:
        try:
            # FFmpegã‚’ä½¿ç”¨ã—ã¦ä½œæˆæ—¥æ™‚ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            cmd = [
                "ffprobe",
                "-v", "quiet",
                "-print_format", "json",
                "-show_format",
                tmp_path
            ]
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
            metadata = json.loads(result.stdout)
            
            # ä½œæˆæ—¥æ™‚ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if 'format' in metadata and 'tags' in metadata['format']:
                tags = metadata['format']['tags']
                # æ§˜ã€…ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
                for date_key in ['creation_time', 'date', 'creation_date', 'datetime']:
                    if date_key in tags:
                        creation_date = tags[date_key]
                        break
            
            if creation_date:
                # ISO å½¢å¼ã«å¤‰æ›ã€'T'ã§åˆ†å‰²ã—ã¦æ—¥ä»˜éƒ¨åˆ†ã ã‘ã‚’å–å¾—
                try:
                    # æ§˜ã€…ãªæ—¥ä»˜å½¢å¼ã«å¯¾å¿œ
                    if 'T' in creation_date:
                        creation_date = creation_date.split('T')[0]  # ISOå½¢å¼ã®å ´åˆ
                    elif ' ' in creation_date:
                        creation_date = creation_date.split(' ')[0]  # ç©ºç™½åŒºåˆ‡ã‚Šã®å ´åˆ
                    
                    # YYYY:MM:DDå½¢å¼ã‚’YYYY-MM-DDã«å¤‰æ›
                    if ':' in creation_date and creation_date.count(':') >= 2:
                        parts = creation_date.split(':')
                        if len(parts[0]) == 4:  # YYYYå½¢å¼ã®å¹´ã®å ´åˆ
                            creation_date = f"{parts[0]}-{parts[1]}-{parts[2]}"
                except:
                    # æ—¥ä»˜å½¢å¼ã®å¤‰æ›å¤±æ•—ã®å ´åˆã¯ç„¡è¦–
                    pass
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã‚’ä½¿ç”¨
            if not creation_date:
                file_stat = os.stat(tmp_path)
                creation_date = datetime.fromtimestamp(file_stat.st_mtime).strftime('%Y-%m-%d')
        except Exception as e:
            st.warning(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    try:
        os.unlink(tmp_path)
    except:
        pass
    
    return filename, creation_date

def split_text_for_notion(text, max_length=2000):
    """
    é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’Notionã®åˆ¶é™ã«åˆã‚ã›ã¦åˆ†å‰²ã—ã¾ã™
    :param text: åˆ†å‰²ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
    :param max_length: ãƒ–ãƒ­ãƒƒã‚¯ã‚ãŸã‚Šã®æœ€å¤§æ–‡å­—æ•°
    :return: åˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
    """
    if len(text) <= max_length:
        return [text]
    
    # æ–‡ç« ã‚’åˆ†å‰²
    chunks = []
    for i in range(0, len(text), max_length):
        chunks.append(text[i:i + max_length])
    
    return chunks

def split_audio_ffmpeg(input_file, chunk_duration=300, output_dir=None):
    """
    FFmpegã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã•ã‚ŒãŸé•·ã•ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5åˆ†ï¼‰
    """
    if output_dir is None:
        output_dir = tempfile.mkdtemp()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’å–å¾—
    file_ext = os.path.splitext(input_file)[1].lower()
    output_format = "wav"  # å‡ºåŠ›ã¯å¸¸ã«WAVå½¢å¼
    
    # FFmpegã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰
    cmd = [
        "ffmpeg",
        "-i", input_file,
        "-f", "segment",
        "-segment_time", str(chunk_duration),
        "-c:a", "pcm_s16le",  # 16-bit PCM
        "-ar", "16000",       # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ16kHz
        f"{output_dir}/chunk_%03d.{output_format}"
    ]
    
    try:
        # FFmpegã‚’å®Ÿè¡Œï¼ˆå‡ºåŠ›ã‚’éè¡¨ç¤ºï¼‰
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        # ç”Ÿæˆã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
        chunk_files = sorted([
            os.path.join(output_dir, f) for f in os.listdir(output_dir)
            if f.startswith("chunk_") and f.endswith(f".{output_format}")
        ])
        
        return chunk_files
    except subprocess.CalledProcessError as e:
        st.error(f"FFmpegã«ã‚ˆã‚‹éŸ³å£°åˆ†å‰²ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if e.stderr:
            st.error(f"FFmpeg ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {e.stderr.decode()}")
        raise e

def transcribe_audio(file, api_key, model="whisper-1", language="ja"):
    """
    OpenAI Whisper APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹
    """
    try:
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        client = OpenAI(api_key=api_key)
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.name).suffix) as tmp_file:
            tmp_file.write(file.getvalue())
            tmp_path = tmp_file.name
        
        file_size = os.path.getsize(tmp_path)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒåˆ¶é™ã‚’è¶…ãˆã‚‹å ´åˆã¯åˆ†å‰²ã—ã¦å‡¦ç†
        if file_size > MAX_SIZE:
            st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ï¼ˆ{file_size/1024/1024:.2f}MBï¼‰ã€åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")
            
            # FFmpegãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
            ffmpeg_available = False
            try:
                subprocess.run(["ffmpeg", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
                ffmpeg_available = True
            except (subprocess.SubprocessError, FileNotFoundError):
                st.error("éŸ³å£°åˆ†å‰²ã«ã¯FFmpegãŒå¿…è¦ã§ã™ã€‚Streamlit Cloudã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ25MBä»¥ä¸‹ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ãŒå¯¾å¿œå¯èƒ½ã§ã™ã€‚")
                raise Exception("FFmpegãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚ˆã‚Šå°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã§è©¦ã—ã¦ãã ã•ã„ã€‚")
            
            if not ffmpeg_available:
                raise Exception("FFmpegãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚ˆã‚Šå°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã§è©¦ã—ã¦ãã ã•ã„ã€‚")
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¤‡æ•°ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            temp_dir = tempfile.mkdtemp()
            try:
                chunk_files = split_audio_ffmpeg(tmp_path, output_dir=temp_dir)
                
                full_text = ""
                all_segments = []
                
                # å„ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
                for i, chunk_file in enumerate(chunk_files):
                    st.info(f"ãƒãƒ£ãƒ³ã‚¯ {i+1}/{len(chunk_files)} ã‚’å‡¦ç†ä¸­...")
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                    chunk_size = os.path.getsize(chunk_file)
                    st.info(f"ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size/1024/1024:.2f}MB")
                    
                    with open(chunk_file, "rb") as audio_file:
                        try:
                            transcript = client.audio.transcriptions.create(
                                model=model,
                                file=audio_file,
                                language=language,
                                response_format="verbose_json"
                            )
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã‚’çµåˆ
                            if hasattr(transcript, 'text'):
                                full_text += transcript.text + "\n"
                            
                            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒã‚ã‚Œã°è¿½åŠ 
                            if hasattr(transcript, 'segments'):
                                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ™‚é–“ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’èª¿æ•´
                                time_offset = (i * 300)  # 5åˆ†ï¼ˆ300ç§’ï¼‰ã”ã¨ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ
                                for segment in transcript.segments:
                                    if hasattr(segment, 'start'):
                                        segment.start += time_offset
                                    if hasattr(segment, 'end'):
                                        segment.end += time_offset
                                all_segments.extend(transcript.segments)
                        except Exception as e:
                            st.error(f"ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                            continue
                    
                    # å‡¦ç†æ¸ˆã¿ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤
                    try:
                        os.remove(chunk_file)
                    except:
                        pass
                
                # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                try:
                    os.rmdir(temp_dir)
                except:
                    pass
                
                # å…ƒã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
                try:
                    os.unlink(tmp_path)
                except:
                    pass
                
                return full_text, all_segments
            except Exception as e:
                st.error(f"éŸ³å£°åˆ†å‰²å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                raise e
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„å ´åˆã¯ç›´æ¥å‡¦ç†
            with open(tmp_path, "rb") as audio_file:
                transcript = client.audio.transcriptions.create(
                    model=model,
                    file=audio_file,
                    language=language,
                    response_format="verbose_json"
                )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            os.unlink(tmp_path)
            
            return transcript.text, getattr(transcript, "segments", [])
    except Exception as e:
        st.error(f"æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise e

def generate_markdown(text, segments):
    """
    æ–‡å­—èµ·ã“ã—çµæœã‚’Markdownå½¢å¼ã«æ•´å½¢ã—ã¾ã™ã€‚
    """
    md = "# éŸ³å£°æ–‡å­—èµ·ã“ã—çµæœ\n\n"
    if text:
        md += "## å…¨ä½“ãƒ†ã‚­ã‚¹ãƒˆ\n\n" + text + "\n\n"
    else:
        md += "å…¨ä½“ã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n\n"
    
    if segments:
        md += "## ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥æ–‡å­—èµ·ã“ã—\n\n"
        for seg in segments:
            start = getattr(seg, "start", 0)
            end = getattr(seg, "end", 0)
            text = getattr(seg, "text", "").strip()
            md += f"- **[{start:.2f}ç§’ ï½ {end:.2f}ç§’]**: {text}\n"
    else:
        md += "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n"
    return md

def generate_summary(text, api_key):
    """
    æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    :param text: æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ
    :param api_key: OpenAI APIã‚­ãƒ¼
    :return: ã‚µãƒãƒªãƒ¼æ–‡ç« 
    """
    prompt = f"""
ä»¥ä¸‹ã¯ä¼šè­°ã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ã¾ã¨ã‚ãŸè­°äº‹éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
è­°äº‹éŒ²ã«ã¯ä»¥ä¸‹ã®æƒ…å ±ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. ä¼šè­°ã®ä¸»ãªè­°é¡Œ
2. è­°è«–ã•ã‚ŒãŸé‡è¦ãªãƒã‚¤ãƒ³ãƒˆ
3. æ±ºå®šäº‹é …
4. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆæ‹…å½“è€…ã¨æœŸé™ãŒã‚ã‹ã‚‹å ´åˆï¼‰
5. æ¬¡å›ã®ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—é …ç›®ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰

å½¢å¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ã—ã¦ãã ã•ã„ï¼š
- ç°¡æ½”ã‹ã¤æ˜ç¢ºã«
- ç®‡æ¡æ›¸ãã§ã¾ã¨ã‚ã‚‹
- å†…å®¹ã¯ä¼šè­°ã®å®Ÿè³ªçš„ãªæƒ…å ±ã ã‘ã‚’å«ã‚ã‚‹

æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ:
"""
    prompt += text

    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ä¼šè­°ã®è­°äº‹éŒ²ã‚’è¦ç´„ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚æ§‹é€ çš„ã§ç°¡æ½”ã€ã‹ã¤é‡è¦ãªãƒã‚¤ãƒ³ãƒˆãŒæ˜ç¢ºã«ã‚ã‹ã‚‹ã‚ˆã†ã«æƒ…å ±ã‚’ã¾ã¨ã‚ã¾ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )
        
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise e

def write_to_notion(api_key, database_id, title, transcription, summary, filename, file_date):
    """
    Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ–°è¦ãƒšãƒ¼ã‚¸ã¨ã—ã¦æ–‡å­—èµ·ã“ã—çµæœã¨ã‚µãƒãƒªãƒ¼ã‚’æ›¸ãè¾¼ã¿ã¾ã™ã€‚
    :param api_key: Notion API ã‚­ãƒ¼
    :param database_id: æ›¸ãè¾¼ã¿å…ˆã®Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ID
    :param title: è­°äº‹éŒ²ã®ã‚¿ã‚¤ãƒˆãƒ«
    :param transcription: æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ
    :param summary: ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ
    :param filename: å…ƒã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å
    :param file_date: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆæ—¥æ™‚
    :return: æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    try:
        notion = Client(auth=api_key)
        
        # Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€åˆã®ã‚«ãƒ©ãƒ ï¼ˆé€šå¸¸ã¯ã‚¿ã‚¤ãƒˆãƒ«å‹ï¼‰ã«ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
        # Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’è‡ªå‹•çš„ã«èª¿ã¹ã‚‹
        try:
            db_info = notion.databases.retrieve(database_id)
            properties = {}
            
            # ã‚¿ã‚¤ãƒˆãƒ«ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¨æ—¥ä»˜ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’è¦‹ã¤ã‘ã‚‹
            title_property = None
            date_property = None
            
            for prop_name, prop_info in db_info['properties'].items():
                if prop_info['type'] == 'title' and title_property is None:
                    title_property = prop_name
                elif prop_info['type'] == 'date' and date_property is None:
                    date_property = prop_name
            
            # ã‚¿ã‚¤ãƒˆãƒ«ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’è¨­å®šï¼ˆå…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨ï¼‰
            if title_property:
                properties[title_property] = {
                    "title": [
                        {
                            "text": {
                                "content": filename
                            }
                        }
                    ]
                }
            else:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¿ã‚¤ãƒˆãƒ«å‹ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            # æ—¥ä»˜ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒã‚ã‚Œã°è¨­å®šï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆæ—¥æ™‚ã‚’ä½¿ç”¨ï¼‰
            if date_property and file_date:
                properties[date_property] = {
                    "date": {
                        "start": file_date
                    }
                }
            
            # ãƒšãƒ¼ã‚¸ã®å­ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½œæˆ
            children = [
                {
                    "object": "block",
                    "type": "heading_2", 
                    "heading_2": {
                        "rich_text": [{
                            "type": "text", 
                            "text": {"content": "ä¼šè­°è¦ç´„"}
                        }]
                    }
                }
            ]
            
            # ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ–ãƒ­ãƒƒã‚¯ã«è¿½åŠ 
            summary_chunks = split_text_for_notion(summary)
            for chunk in summary_chunks:
                children.append({
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{
                            "type": "text", 
                            "text": {"content": chunk}
                        }]
                    }
                })
            
            # æ–‡å­—èµ·ã“ã—è¦‹å‡ºã—ã‚’è¿½åŠ 
            children.append({
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{
                        "type": "text", 
                        "text": {"content": "æ–‡å­—èµ·ã“ã—å…¨æ–‡"}
                    }]
                }
            })
            
            # æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦è¿½åŠ 
            transcription_chunks = split_text_for_notion(transcription)
            for chunk in transcription_chunks:
                children.append({
                    "object": "block", 
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{
                            "type": "text", 
                            "text": {"content": chunk}
                        }]
                    }
                })
            
            # æ–°ã—ã„ãƒšãƒ¼ã‚¸ã‚’ä½œæˆ
            new_page = notion.pages.create(
                parent={"database_id": database_id},
                properties=properties,
                children=children
            )
            
            return f"Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ–°è¦ãƒšãƒ¼ã‚¸ã¨ã—ã¦è­°äº‹éŒ²ã‚’ä½œæˆã—ã¾ã—ãŸã€‚æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã¯{len(transcription_chunks)}å€‹ã®ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ã•ã‚Œã¾ã—ãŸã€‚"
            
        except Exception as e:
            return f"Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            
    except Exception as e:
        return f"Notionã¸ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def main():
    st.set_page_config(page_title="ä¼šè­°éŒ²ä½œæˆã‚¢ãƒ—ãƒª", page_icon="ğŸ“", layout="wide")
    st.title("ä¼šè­°éŒ²ä½œæˆã‚¢ãƒ—ãƒª")
    
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ã‚’ç¢ºèª
    if not check_password():
        st.stop()  # èªè¨¼ãŒé€šã‚‰ãªã‘ã‚Œã°ã“ã“ã§å‡¦ç†ã‚’ä¸­æ–­
    
    try:
        config = load_config()
        api_key = config.get("openai", {}).get("api_key")
        notion_api_key = config.get("notion", {}).get("api_key")
        notion_database_id = config.get("notion", {}).get("database_id")
        
        if not api_key:
            st.error("Streamlit Secretsã‹ã‚‰ OpenAI APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # Notionè¨­å®šã®ç¢ºèª
        notion_configured = notion_api_key and notion_database_id
    except Exception as e:
        st.error(f"è¨­å®šã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    uploaded_file = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ (mp4, m4a, wav)", type=["mp4", "m4a", "wav"])
    meeting_title = st.text_input("ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«", "è­°äº‹éŒ²")
    
    if uploaded_file is not None:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        filename, file_date = get_file_metadata(uploaded_file)
        st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å: {filename}, ä½œæˆæ—¥æ™‚: {file_date}")
        
        with st.spinner("æ–‡å­—èµ·ã“ã—ä¸­..."):
            try:
                # ç›´æ¥Whisper APIã‚’ä½¿ç”¨ã—ã¦æ–‡å­—èµ·ã“ã—
                transcription_text, segments = transcribe_audio(uploaded_file, api_key=api_key)
                
                # ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
                with st.spinner("ä¼šè­°å†…å®¹ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆä¸­..."):
                    summary_text = generate_summary(transcription_text, api_key=api_key)
                
                # çµæœã®è¡¨ç¤º
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### ä¼šè­°ã‚µãƒãƒªãƒ¼")
                    st.markdown(summary_text)
                    
                with col2:
                    st.markdown("### æ–‡å­—èµ·ã“ã—çµæœ")
                    st.markdown(transcription_text[:1000] + "..." if len(transcription_text) > 1000 else transcription_text)
                    if len(transcription_text) > 1000:
                        with st.expander("å…¨æ–‡ã‚’è¡¨ç¤º"):
                            st.markdown(transcription_text)
                
                # Markdownãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ãƒœã‚¿ãƒ³
                full_markdown = f"# {meeting_title}\n\n## ä¼šè­°ã‚µãƒãƒªãƒ¼\n\n{summary_text}\n\n## æ–‡å­—èµ·ã“ã—å…¨æ–‡\n\n{transcription_text}"
                st.download_button(
                    label="Markdownãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=full_markdown,
                    file_name=f"{meeting_title}_{datetime.now().strftime('%Y%m%d')}.md",
                    mime="text/markdown"
                )
                
                # Notionã¸ã®æ›¸ãè¾¼ã¿ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                if notion_configured:
                    if st.button("Notionã«è­°äº‹éŒ²ã‚’ä¿å­˜"):
                        with st.spinner("Notionã«ä¿å­˜ä¸­..."):
                            result = write_to_notion(
                                notion_api_key, 
                                notion_database_id, 
                                meeting_title, 
                                transcription_text, 
                                summary_text,
                                filename,
                                file_date
                            )
                            st.success(result)
                else:
                    st.warning("Notionã¸ã®ä¿å­˜æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€Streamlit Secretsã« Notionã®è¨­å®šæƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    
            except Exception as e:
                st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

if __name__ == "__main__":
    main()
